= Automate your deployment with Tekton
So far we exercised what we call the Inner-loop development workflow where you essentially iteratively do code, build, test, debug, deploy in a local environment (or a Dev Workspace in our case). But how about the build and deployment after we push our code to a Git repository?

In this section you are going to learn how to automate the build and deployment of your Integrations using a Cloud Native https://www.redhat.com/en/topics/devops/what-is-ci-cd[CI/CD technology] called https://tekton.dev[Tekton]. Tekton is available on Openshift through the Openshift Pipelines Operator which is already present on our cluster.

== Automating the Camel K deployment 
We learned that Camel K does a great job containerizing our Integrations and deploying on Openshift. Now we are going to learn how to integrate it with Openshift Pipelines so you can leverage CI/CD tools to delivery integrations following corporate standards.

Lets deploy the `Order Connector` integration service we developed in `module-02`. 

[NOTE]
====
If you have not created a `ConfigMap` for the `Order Connector` integration during module-02, please do it before triggering the Pipeline run.

Run the follwoing command in the Workspace Terminal
[source,bash]
=====
oc create configmap order-connector-config --from-file=$PROJECT_SOURCE/module-02/order-connector/application.properties -n {user}-camel
=====
====

A Camel K Pipeline has been already created for you, to trigger it go to the Pipelines view on Openshift Console (Developer Perspective), click on `camel-k-pipeline`, then select `Actions` -> `start`. Then enter the parameters as follow.

 * `repo-url`: `leave as is`
 * `repo-branch`: `main` (if you didn't complete module-02, enter `solution`)
 * `filename`: `module-02/order-connector/order-connector.camel.yaml`
 * `traits`: `leave it as is`
 * `dependencies`: `-d camel:http -p configmap:order-connector-config`
 * `Workspaces -> shared-data`: `PersistentVolumeClaim` -> `PVC source-code` (select from the drop-down list)

See these steps in action here.

image::module04/camel-k-pipeline-run.gif[]

After the `Pipeline run` completes successfully you should be able to check a new Camel POD running in the topology view. Click on the POD and see the Container logs to check the integration startup as follows.

image::module04/camel-k-pod-topology.gif[]

[NOTE]
====
In this exercise we triggered the Pipeline manually, but in practice you would have a **Webhook** in place so the Pipeline can run **continuously** every time a new change gets pushed to the integration code Git repository. In case you are interested in the Pipeline Triggering capability check https://www.redhat.com/en/blog/guide-to-openshift-pipelines-part-6-triggering-pipeline-execution-from-github[this tutorial] out for reference.
====

You can use this same Pipeline to build and deploy all other integrations we created previously by just passing the correct `filename` and `dependencies` parameters.

== Automating the Camel K deployment 
We learned that Camel K does a great job containerizing our Integrations and deploying on Openshift. Now we are going to learn how to integrate it with Openshift Pipelines so you can leverage CI/CD tools to delivery integrations following corporate standards.

Lets deploy the `Order Connector` integration service we developed in `module-02`. 
