= Automate your deployment with Tekton
So far we exercised what we call the Inner-loop development workflow where you essentially iteratively do code, build, test, debug, deploy in a local environment (or a Dev Workspace in our case). But how about the build and deployment after we push our code to a Git repository?

In this section you are going to learn how to automate the build and deployment of your Integrations using a Cloud Native https://www.redhat.com/en/topics/devops/what-is-ci-cd[CI/CD technology^] called https://tekton.dev[Tekton^]. Tekton is available on Openshift through the Openshift Pipelines Operator which is already present on our cluster.

== Automating the Camel K deployment 
We learned that Camel K does a great job containerizing our Integrations and deploying on Openshift. Now we are going to learn how to integrate it with Openshift Pipelines so you can leverage CI/CD tools to delivery integrations following corporate standards.

Lets deploy the `Order Connector` integration service we developed in `module-02`. 

[NOTE]
====
If you have not created a `ConfigMap` for the `Order Connector` integration during module-02, please do it before triggering the Pipeline run.

Run the following command in your DevWorkspace Terminal
[source,sh,role="copypaste",subs=attributes+]
....
oc create configmap order-connector-config --from-file=$PROJECT_SOURCE/module-02/order-connector/application.properties -n {user}-camel

# in case you choose one of the other services
# customer-connector
oc create configmap customer-connector-config --from-file=$PROJECT_SOURCE/module-02/customer-connector/application.properties -n {user}-camel

# customer-service
oc create configmap customer-service-config --from-file=$PROJECT_SOURCE/module-02/customer-service/application.properties -n {user}-camel

oc create configmap customer-openapi-spec --from-file=$PROJECT_SOURCE/module-02/customer-service/customer-openapi-spec.json -n {user}-camel
....
====

A Camel K Pipeline has been already created for you, to trigger it go to the **Pipelines** view on Openshift Console (Developer Perspective), click on `camel-k-pipeline`, then select `Actions` -> `Start`. Then enter the parameters as follow.

[IMPORTANT]
====
You may have the integration services already deployed/running inside the `{user}-camel` project/namespace. They were deployed as part of module-02 using `kamel run` CLI tool. Please check if they are deployed and remove them before you proceed. 

To check there is any integration already deployed ad running inside `{user}-camel` project execute this command inside your DevWorkspace Terminal
[source,sh,role="copypaste",subs=attributes+]
....
kamel get -n {user}-camel
....

To remove deployed integrations

[source,sh,role="copypaste",subs=attributes+]
....
#to remove specific integration
kamel delete order-connector -n {user}-camel
kamel delete customer-connector -n {user}-camel
....
====

.Pipeline parameters
[%autowidth, cols="d,l"]
|===
|Name|Value

|repo-url|leave as is
|repo-branch|main (if you didn't complete module-02, enter solution)
|filename|module-02/order-connector/order-connector.camel.yaml
|traits|leave it as is
|dependencies|-d camel:http -p configmap:order-connector-config
|Workspaces -> shared-data|PersistentVolumeClaim -> PVC source-code (select from the drop-down list)
|===

See these steps in action here.

image::module04/camel-k-pipeline-run.gif[]

After the `Pipeline run` completes successfully you should be able to check a new Camel POD running in the topology view. Click on the POD and see the Container logs to check the integration startup as follows.

image::module04/camel-k-pod-topology.gif[]

[TIP]
====
In this exercise we triggered the Pipeline manually, but in practice you would have a **Webhook** in place so the Pipeline can run **continuously** every time a new change gets pushed to the integration code Git repository. In case you are interested in the Pipeline Triggering capability check https://www.redhat.com/en/blog/guide-to-openshift-pipelines-part-6-triggering-pipeline-execution-from-github[this tutorial^] out for reference.
====

[NOTE]
====
You can use this same Pipeline to build and deploy all other integrations we created previously by just passing the correct `filename` and `dependencies` parameters.

 * for the `customer-service` the parameters are:

.Pipeline parameters
[%autowidth, cols="d,l"]
|===
|Name|Value

|filename|module-02/customer-service/customer-service.camel.yaml
|dependencies|-d camel:platform-http -d mvn:org.postgresql:postgresql:42.7.3 -p configmap:customer-service-config --open-api configmap:customer-openapi-spec
|===

 * for the `customer-connector` the parameters are:

.Pipeline parameters
[%autowidth, cols="d,l"]
|===
|Name|Value

|filename|module-02/customer-connector/customer-connector.camel.yaml
|dependencies|-d camel:http -p configmap:customer-connector-config
|===
====


With that we conclude this module-04! Congratulations!